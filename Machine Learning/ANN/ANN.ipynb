{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afab142f",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks (ANN)\n",
    "\n",
    "An Artificial Neural Network (ANN) is a computational model inspired by the structure and functioning of the human brain. It utilizes interconnected layers of nodes, often called neurons, to process information and learn from data.\n",
    "\n",
    "The process begins with the **input layer**, which receives the raw data. This information then flows through one or more **hidden layers**. In these layers, each neuron applies a set of **weights** to its inputs, sums these weighted inputs, and then passes the sum through an **activation function**. This transformation process continues, with the data propagating forward until it reaches the **output layer**. The output layer produces the final result, which could be a prediction, classification, or another type of output depending on the task.\n",
    "\n",
    "The network \"learns\" through a process called **backpropagation**. This involves calculating the error (the difference between the predicted output and the actual target output) at the output layer. This error is then systematically propagated backward through the network, and the connection weights between neurons are adjusted to minimize this error. Complex ANNs are capable of recognizing intricate patterns and relationships within data that simpler models might not detect, making them powerful tools for a wide variety of prediction tasks.\n",
    "\n",
    "#### Pros\n",
    "* Exceptional ability to model complex non-linear relationships\n",
    "* Capable of automatic feature extraction, reducing the need for manual feature engineering\n",
    "* Highly adaptable to different types of problems and data structures\n",
    "* Can achieve state-of-the-art performance on many challenging tasks\n",
    "* Handles high-dimensional data efficiently\n",
    "* Can be transfer-learned from pre-trained models to new domains\n",
    "\n",
    "#### Cons\n",
    "* Often requires large amounts of training data to perform well\n",
    "* Training can be computationally intensive and time-consuming\n",
    "* Prone to overfitting without proper regularization techniques\n",
    "* Limited interpretability (\"black box\" nature) compared to simpler models\n",
    "* Requires careful hyperparameter tuning and architecture design\n",
    "* May struggle with small datasets relative to the number of parameters\n",
    "\n",
    "\n",
    "#### Key Components & Concepts\n",
    "\n",
    "##### Activation Functions\n",
    "\n",
    "Activation functions introduce non-linearity into the network, allowing it to learn complex patterns.\n",
    "\n",
    "| Activation                      | Use Case                        | Formula/Description                          |\n",
    "| :------------------------------ | :------------------------------ | :------------------------------------------- |\n",
    "| **ReLU** (Rectified Linear Unit) | Default for hidden layers       | `$f(x) = \\max(0, x)$`                         |\n",
    "| **Sigmoid** | Binary classification output    | `$f(x) = \\frac{1}{1 + e^{-x}}$`                |\n",
    "| **Tanh** (Hyperbolic Tangent)   | Output between -1 and 1         | `$f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$` |\n",
    "| **Softmax** | Multi-class classification output | Converts outputs to probabilities            |\n",
    "| **Linear** | Regression output               | `$f(x) = x$`                                 |\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Task-Specific Configurations\n",
    "\n",
    "The choice of output activation and loss function depends on the specific task.\n",
    "\n",
    "| Task                       | Output Activation | Loss Function                 |\n",
    "| :------------------------- | :---------------- | :---------------------------- |\n",
    "| Binary Classification      | `sigmoid`         | `binary_crossentropy`         |\n",
    "| Multi-Class Classification | `softmax`         | `categorical_crossentropy`    |\n",
    "| Regression                 | `linear`          | `mean_squared_error` or `mae` |\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Data Preprocessing & Handling\n",
    "\n",
    "Proper data preparation is crucial for training effective ANNs.\n",
    "\n",
    "| Concept                    | Why It Matters                                         | Tools / Methods                     | Notes                                         |\n",
    "| :------------------------- | :----------------------------------------------------- | :---------------------------------- | :---------------------------------------------- |\n",
    "| **Normalization** | Speeds up convergence and avoids exploding gradients     | `StandardScaler`, `MinMaxScaler`    | Use before training                             |\n",
    "| **One-hot Encoding** | Converts categorical data into numerical format        | `pd.get_dummies`, `OneHotEncoder`   | Needed for classification                     |\n",
    "| **Train-Test Split** | Ensures model is evaluated fairly on unseen data         | `train_test_split()`                | Typical ratio: 80/20 or 70/30                   |\n",
    "| **Shuffling** | Avoids learning sequence bias                          | `shuffle=True` in `fit()`           | Especially important for time-irrelevant data   |\n",
    "| **Handling Imbalanced Data** | Prevents biased predictions towards the majority class | SMOTE, class weights, resampling    | Use for classification tasks with uneven classes|\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Loss Functions in TensorFlow\n",
    "\n",
    "Loss functions measure how well the model's predictions match the actual target values.\n",
    "\n",
    "| Task                       | Loss Function              | TensorFlow Name                |\n",
    "| :------------------------- | :------------------------- | :----------------------------- |\n",
    "| Binary Classification      | Binary Crossentropy        | `'binary_crossentropy'`        |\n",
    "| Multi-Class Classification | Categorical Crossentropy   | `'categorical_crossentropy'`   |\n",
    "| Regression                 | Mean Squared Error (MSE)   | `'mean_squared_error'`         |\n",
    "| Regression (Robust)        | Mean Absolute Error (MAE)  | `'mean_absolute_error'`        |\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Optimizers\n",
    "\n",
    "Optimizers are algorithms used to adjust the weights of the network to minimize the loss function.\n",
    "\n",
    "| Optimizer   | Use Case                      | Notes                             |\n",
    "| :---------- | :---------------------------- | :-------------------------------- |\n",
    "| **SGD** | Simple tasks                  | May converge slowly               |\n",
    "| **Adam** | Default choice                | Adaptive + fast convergence       |\n",
    "| **RMSprop** | Time series / RNNs            | Deals well with sparse data       |\n",
    "| **Adagrad** | Rare features (e.g., NLP)     | Decreases learning rate over time |\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Tips and Tricks for Training ANNs\n",
    "\n",
    "| Trick                        | Why It Helps                                                        |\n",
    "| :--------------------------- | :------------------------------------------------------------------ |\n",
    "| **Use normalization** | Stabilizes gradients and helps faster training                      |\n",
    "| **Use dropout** | Prevents overfitting by randomly dropping neurons during training     |\n",
    "| **Use early stopping** | Stops training when validation performance stalls, preventing overfitting |\n",
    "| **Start small** | Use a small network first; scale up complexity as needed            |\n",
    "| **Plot learning curves** | Understand training vs. validation dynamics (loss/accuracy over epochs) |\n",
    "| **Try multiple activations** | `ReLU` works most of the time, but don’t be afraid to experiment    |\n",
    "| **Tune with validation set** | Avoid overfitting to training data by using a separate validation set |\n",
    "| **Use callbacks** | For checkpoints (saving model periodically) and early stopping in Keras |\n",
    "\n",
    "<br>\n",
    "\n",
    "#### General Workflow for Building an ANN\n",
    "\n",
    "1.  **Preprocess data:**\n",
    "    * Normalize numerical features.\n",
    "    * Encode categorical features (e.g., one-hot encoding).\n",
    "    * Handle missing values.\n",
    "2.  **Split data:**\n",
    "    * Divide the dataset into training and testing sets (e.g., 80% train, 20% test).\n",
    "    * Optionally, create a validation set from the training data.\n",
    "3.  **Build ANN Architecture:**\n",
    "    * Define the layers of the network. A common starting point:\n",
    "        * Input Layer (implicitly defined by the first `Dense` layer's `input_shape`)\n",
    "        * One or more `Dense` hidden layers with `ReLU` activation.\n",
    "        * Output Layer with an activation function appropriate for the task (e.g., `sigmoid` for binary classification, `softmax` for multi-class, `linear` for regression).\n",
    "4.  **Compile the Model:**\n",
    "    * Specify the **Optimizer**: `Adam` is often a good default.\n",
    "    * Specify the **Loss Function**: Choose based on the task (e.g., `binary_crossentropy`, `categorical_crossentropy`, `mean_squared_error`).\n",
    "    * Specify **Metrics**: What to track during training and evaluation (e.g., `accuracy` for classification, `mse` or `mae` for regression).\n",
    "5.  **Fit Model (Train):**\n",
    "    * Train the model on the training data using the `fit()` method.\n",
    "    * Specify the number of `epochs` (passes through the entire training dataset) and `batch_size`.\n",
    "    * Consider using `callbacks` like `EarlyStopping` and `ModelCheckpoint`.\n",
    "    * Provide validation data to monitor performance on unseen data during training.\n",
    "6.  **Evaluate Model:**\n",
    "    * Assess the trained model's performance on the test set using the `evaluate()` method.\n",
    "7.  **Tune Model (Iterate):**\n",
    "    * If performance is not satisfactory, adjust:\n",
    "        * Number of layers and neurons per layer.\n",
    "        * Learning rate of the optimizer.\n",
    "        * Dropout rates for regularization.\n",
    "        * Activation functions.\n",
    "        * Batch size and number of epochs.\n",
    "    * Re-train and re-evaluate.\n",
    "8.  **Save Model (Optional):**\n",
    "    * Once satisfied with the model, save its architecture and weights for future use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\kulas\\AppData\\Local\\Temp\\ipykernel_15940\\109803954.py:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df= pd.read_csv(url, names=column_names, sep=',\\s', engine='python')\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install --quiet tensorflow pandas scikit-learn matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df= pd.read_csv(url, names=column_names, sep=',\\s', engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d845a4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa622369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                  False                False                   False   \n",
       "1                  False                False                   False   \n",
       "2                  False                False                   False   \n",
       "3                  False                False                   False   \n",
       "4                  False                False                   False   \n",
       "\n",
       "   workclass_Private  ...  native-country_Puerto-Rico  \\\n",
       "0              False  ...                       False   \n",
       "1              False  ...                       False   \n",
       "2               True  ...                       False   \n",
       "3               True  ...                       False   \n",
       "4               True  ...                       False   \n",
       "\n",
       "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                    False                 False                  False   \n",
       "1                    False                 False                  False   \n",
       "2                    False                 False                  False   \n",
       "3                    False                 False                  False   \n",
       "4                    False                 False                  False   \n",
       "\n",
       "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                    False                           False   \n",
       "1                    False                           False   \n",
       "2                    False                           False   \n",
       "3                    False                           False   \n",
       "4                    False                           False   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  \\\n",
       "0                          True                   False   \n",
       "1                          True                   False   \n",
       "2                          True                   False   \n",
       "3                          True                   False   \n",
       "4                         False                   False   \n",
       "\n",
       "   native-country_Yugoslavia  income_>50K  \n",
       "0                      False        False  \n",
       "1                      False        False  \n",
       "2                      False        False  \n",
       "3                      False        False  \n",
       "4                      False        False  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.head()\n",
    "# One-hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beeacdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>-1.516792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>-1.516792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>-2.932948</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-0.849080</td>\n",
       "      <td>0.639741</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.197409</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.103983</td>\n",
       "      <td>-0.335433</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>1.423610</td>\n",
       "      <td>-0.358777</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-1.215643</td>\n",
       "      <td>0.110960</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-1.655225</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.983734</td>\n",
       "      <td>0.929893</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>1.888424</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-0.174295</td>\n",
       "      <td>-0.262097</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>-1.516792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>-0.023518</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.045408</td>\n",
       "      <td>-0.022173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0      0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1      0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2     -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3      1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4     -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "32556 -0.849080  0.639741       0.746039     -0.145920      -0.21666   \n",
       "32557  0.103983 -0.335433      -0.420060     -0.145920      -0.21666   \n",
       "32558  1.423610 -0.358777      -0.420060     -0.145920      -0.21666   \n",
       "32559 -1.215643  0.110960      -0.420060     -0.145920      -0.21666   \n",
       "32560  0.983734  0.929893      -0.420060      1.888424      -0.21666   \n",
       "\n",
       "       hours-per-week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0           -0.035429              -0.174295            -0.262097   \n",
       "1           -2.222153              -0.174295            -0.262097   \n",
       "2           -0.035429              -0.174295            -0.262097   \n",
       "3           -0.035429              -0.174295            -0.262097   \n",
       "4           -0.035429              -0.174295            -0.262097   \n",
       "...               ...                    ...                  ...   \n",
       "32556       -0.197409              -0.174295            -0.262097   \n",
       "32557       -0.035429              -0.174295            -0.262097   \n",
       "32558       -0.035429              -0.174295            -0.262097   \n",
       "32559       -1.655225              -0.174295            -0.262097   \n",
       "32560       -0.035429              -0.174295            -0.262097   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "0                   -0.014664          -1.516792  ...   \n",
       "1                   -0.014664          -1.516792  ...   \n",
       "2                   -0.014664           0.659286  ...   \n",
       "3                   -0.014664           0.659286  ...   \n",
       "4                   -0.014664           0.659286  ...   \n",
       "...                       ...                ...  ...   \n",
       "32556               -0.014664           0.659286  ...   \n",
       "32557               -0.014664           0.659286  ...   \n",
       "32558               -0.014664           0.659286  ...   \n",
       "32559               -0.014664           0.659286  ...   \n",
       "32560               -0.014664          -1.516792  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                    -0.033729                   -0.059274   \n",
       "1                    -0.033729                   -0.059274   \n",
       "2                    -0.033729                   -0.059274   \n",
       "3                    -0.033729                   -0.059274   \n",
       "4                    -0.033729                   -0.059274   \n",
       "...                        ...                         ...   \n",
       "32556                -0.033729                   -0.059274   \n",
       "32557                -0.033729                   -0.059274   \n",
       "32558                -0.033729                   -0.059274   \n",
       "32559                -0.033729                   -0.059274   \n",
       "32560                -0.033729                   -0.059274   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                    -0.019201             -0.049628              -0.039607   \n",
       "1                    -0.019201             -0.049628              -0.039607   \n",
       "2                    -0.019201             -0.049628              -0.039607   \n",
       "3                    -0.019201             -0.049628              -0.039607   \n",
       "4                    -0.019201             -0.049628              -0.039607   \n",
       "...                        ...                   ...                    ...   \n",
       "32556                -0.019201             -0.049628              -0.039607   \n",
       "32557                -0.019201             -0.049628              -0.039607   \n",
       "32558                -0.019201             -0.049628              -0.039607   \n",
       "32559                -0.019201             -0.049628              -0.039607   \n",
       "32560                -0.019201             -0.049628              -0.039607   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                    -0.023518                       -0.024163   \n",
       "1                    -0.023518                       -0.024163   \n",
       "2                    -0.023518                       -0.024163   \n",
       "3                    -0.023518                       -0.024163   \n",
       "4                    -0.023518                       -0.024163   \n",
       "...                        ...                             ...   \n",
       "32556                -0.023518                       -0.024163   \n",
       "32557                -0.023518                       -0.024163   \n",
       "32558                -0.023518                       -0.024163   \n",
       "32559                -0.023518                       -0.024163   \n",
       "32560                -0.023518                       -0.024163   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "0                          0.340954               -0.045408   \n",
       "1                          0.340954               -0.045408   \n",
       "2                          0.340954               -0.045408   \n",
       "3                          0.340954               -0.045408   \n",
       "4                         -2.932948               -0.045408   \n",
       "...                             ...                     ...   \n",
       "32556                      0.340954               -0.045408   \n",
       "32557                      0.340954               -0.045408   \n",
       "32558                      0.340954               -0.045408   \n",
       "32559                      0.340954               -0.045408   \n",
       "32560                      0.340954               -0.045408   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "0                      -0.022173  \n",
       "1                      -0.022173  \n",
       "2                      -0.022173  \n",
       "3                      -0.022173  \n",
       "4                      -0.022173  \n",
       "...                          ...  \n",
       "32556                  -0.022173  \n",
       "32557                  -0.022173  \n",
       "32558                  -0.022173  \n",
       "32559                  -0.022173  \n",
       "32560                  -0.022173  \n",
       "\n",
       "[32561 rows x 100 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('income_>50K', axis=1)\n",
    "y = df['income_>50K']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398939a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kulas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.4882 - val_accuracy: 0.8422 - val_loss: 0.3414\n",
      "Epoch 2/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3522 - val_accuracy: 0.8488 - val_loss: 0.3260\n",
      "Epoch 3/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3285 - val_accuracy: 0.8549 - val_loss: 0.3171\n",
      "Epoch 4/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3260 - val_accuracy: 0.8553 - val_loss: 0.3159\n",
      "Epoch 5/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3237 - val_accuracy: 0.8516 - val_loss: 0.3139\n",
      "Epoch 6/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3059 - val_accuracy: 0.8532 - val_loss: 0.3110\n",
      "Epoch 7/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3060 - val_accuracy: 0.8562 - val_loss: 0.3119\n",
      "Epoch 8/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3101 - val_accuracy: 0.8551 - val_loss: 0.3109\n",
      "Epoch 9/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3045 - val_accuracy: 0.8526 - val_loss: 0.3126\n",
      "Epoch 10/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3028 - val_accuracy: 0.8583 - val_loss: 0.3116\n",
      "Epoch 11/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3042 - val_accuracy: 0.8551 - val_loss: 0.3116\n",
      "Epoch 12/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.2999 - val_accuracy: 0.8562 - val_loss: 0.3134\n",
      "Epoch 13/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.2999 - val_accuracy: 0.8566 - val_loss: 0.3098\n",
      "Epoch 14/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.2908 - val_accuracy: 0.8551 - val_loss: 0.3111\n",
      "Epoch 15/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.2936 - val_accuracy: 0.8543 - val_loss: 0.3112\n",
      "Epoch 16/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.2988 - val_accuracy: 0.8568 - val_loss: 0.3108\n",
      "Epoch 17/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.2962 - val_accuracy: 0.8543 - val_loss: 0.3106\n",
      "Epoch 18/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.2891 - val_accuracy: 0.8578 - val_loss: 0.3120\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model with early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=64, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a4a666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,269</span> (106.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,269\u001b[0m (106.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,089</span> (35.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,089\u001b[0m (35.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,180</span> (71.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,180\u001b[0m (71.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d313bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.93      0.91      4942\n",
      "        True       0.75      0.63      0.69      1571\n",
      "\n",
      "    accuracy                           0.86      6513\n",
      "   macro avg       0.82      0.78      0.80      6513\n",
      "weighted avg       0.86      0.86      0.86      6513\n",
      "\n",
      "[[4611  331]\n",
      " [ 579  992]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype('int32')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
